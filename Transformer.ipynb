{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer.ipynb","provenance":[],"collapsed_sections":["pm6HR3LMpe-3","lfgp0vO46lrb","5Hn61dMGEUP-","Kd1QUaEu6sA3","qIqDY_ZiWVgg"],"mount_file_id":"17LZM43Ye0EbvwKzS_AIPDAfBJGyL1mc-","authorship_tag":"ABX9TyMRgkuNtJnRAVsXxufXBw6m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pm6HR3LMpe-3","colab_type":"text"},"source":["##Check GPU \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"6B8uQCMnYKi7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1597923113484,"user_tz":-120,"elapsed":18333,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}},"outputId":"acbaf08a-8466-4c39-8d68-ef440aa65e62"},"source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm() "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=f3c07cf3f6b6e8c86dd9d23f9985b0e4b3995a487335a79c24e625a37bf7dd53\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.8 GB  | Proc size: 111.6 MB\n","GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZIqwTtCeYiHl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597923113485,"user_tz":-120,"elapsed":18327,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbaA72Iu3e0G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1597923113486,"user_tz":-120,"elapsed":18320,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}},"outputId":"537ae3f3-3dcd-40c9-d0a9-004c6cb65d0f"},"source":["cd ..\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JSFQmCB11lvE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1597923115890,"user_tz":-120,"elapsed":20717,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}},"outputId":"9cb50892-9eec-40e7-9d45-bb7f993f6f63"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Thu Aug 20 11:31:53 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JHVz1biFYCg5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1597923118484,"user_tz":-120,"elapsed":23304,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}},"outputId":"f906d47c-0ffd-4a1f-8ecc-af3d2b28fff2"},"source":["!kill process_id"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/bin/bash: line 0: kill: process_id: arguments must be process or job IDs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AHiuPPYd3oif","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1597923121353,"user_tz":-120,"elapsed":26166,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}},"outputId":"c9b3b405-883a-4f1b-999b-60e5051bbc7a"},"source":["ls\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mbin\u001b[0m/      \u001b[01;34mdev\u001b[0m/   \u001b[01;34mlib32\u001b[0m/  \u001b[01;34mopt\u001b[0m/   \u001b[01;34msbin\u001b[0m/   \u001b[01;34mtensorflow-1.15.2\u001b[0m/  \u001b[01;34mvar\u001b[0m/\n","\u001b[01;34mboot\u001b[0m/     \u001b[01;34metc\u001b[0m/   \u001b[01;34mlib64\u001b[0m/  \u001b[01;34mproc\u001b[0m/  \u001b[01;34msrv\u001b[0m/    \u001b[30;42mtmp\u001b[0m/\n","\u001b[01;34mcontent\u001b[0m/  \u001b[01;34mhome\u001b[0m/  \u001b[01;34mmedia\u001b[0m/  \u001b[01;34mroot\u001b[0m/  \u001b[01;34mswift\u001b[0m/  \u001b[01;34mtools\u001b[0m/\n","\u001b[01;34mdatalab\u001b[0m/  \u001b[01;34mlib\u001b[0m/   \u001b[01;34mmnt\u001b[0m/    \u001b[01;34mrun\u001b[0m/   \u001b[01;34msys\u001b[0m/    \u001b[01;34musr\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kGPLjeqP329I","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597923121357,"user_tz":-120,"elapsed":26167,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[""],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lfgp0vO46lrb","colab_type":"text"},"source":["##Loading the Data"]},{"cell_type":"code","metadata":{"id":"2NRWVqHTRJGg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597923146670,"user_tz":-120,"elapsed":51477,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["import numpy as np\n","from torch.utils.data import Dataset\n","import torch \n","from torch import nn\n","from torch import optim\n","import copy \n","import matplotlib.pyplot as plt\n","from torch.autograd import Variable \n","import numpy as np\n"," \n","data = np.load('/content/drive/My Drive/data.gz').reshape(-1,700,57)\n","train,label = np.split(data,[22],axis=2)\n","label = label[:,:,0:8]\n","ss_label = label[:,:,0:13]\n","\n","train, test = np.split(train,[5000],axis=0)\n","test, val = np.split(test,[267],0)\n","\n","label, test_label = np.split(label,[5000],axis=0)\n","test_label, val_label = np.split(test_label,[267],0)\n","\n","ss_label, ss_test_label = np.split(ss_label,[5000],axis=0)\n","ss_test_label, ss_val_label = np.split(ss_test_label,[267],0)\n","#train1, train2 = np.split(train,[350],axis=1)\n","#label1, label2 = np.split(label,[350],axis=1)\n","\n","#label1 = torch.tensor(label1,dtype=torch.int64)\n","#label2 = torch.tensor(label2,dtype=torch.int64)\n","\n","#train1 = torch.tensor(train1,dtype=torch.float64)\n","#train2 = torch.tensor(train2,dtype=torch.float64)\n","\n","#print(train1.shape,label1.shape)\n","\n","\n","#print(label[0,0:10,:])\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"QdI1kRHzGM_3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1597923146696,"user_tz":-120,"elapsed":51496,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}},"outputId":"30554776-34ff-4100-ac84-0d5fe557d97e"},"source":["p"],"execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-6c10289a8da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"5Hn61dMGEUP-","colab_type":"text"},"source":["##Generate the Three State Labels"]},{"cell_type":"code","metadata":{"id":"bAqrY4WnDEFV","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146679,"user_tz":-120,"elapsed":51476,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["#Generate the three state labels\n","label_3 = np.roll(label,-1,2)\n","test_label_3 = np.roll(test_label,-1,2)\n","val_label_3 = np.roll(val_label,-1,2)\n","\n","\n","def transfer_to_three(eight, num_seq):\n","    #e1, e2, e3 = np.split(eight,axis=2,indices_or_sections=np.array([2,5]))\n","    #for n in [e1,e2,e3]:\n","    #    n = n.tolist()\n","    eight = eight.tolist()\n","    for i in range(num_seq):\n","        for j in range(700):\n","           if 1 in eight[i][j][0:2]:\n","              eight[i][j] = [1,0,0]\n","           elif 1 in eight[i][j][2:5]:\n","              eight[i][j] = [0,1,0]\n","           elif 1 in eight[i][j][5:8]:\n","              eight[i][j] = [0,0,1] \n","           else:\n","              eight[i][j] = [0,0,0]\n","    \n","    #e1 = torch.tensor(e1,dtype=torch.int64)\n","    #e2 = torch.tensor(e2,dtype=torch.int64)\n","    #e3 = torch.tensor(e3,dtype=torch.int64)\n","    #eight = torch.cat((e1,e2,e3),dim = 1)\n","    return eight\n","\n","test_label_3 = torch.tensor(transfer_to_three(test_label_3,267),dtype=torch.int64)\n","label_3 = torch.tensor(transfer_to_three(label_3,5000),dtype=torch.int64)\n","val_label_3 = torch.tensor(transfer_to_three(val_label_3,267),dtype=torch.int64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uP54srIfyiAP","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146679,"user_tz":-120,"elapsed":51474,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["label = torch.tensor(label,dtype=torch.int64)\n","train = torch.tensor(train,dtype=torch.float64)\n","test_label = torch.tensor(test_label,dtype=torch.int64)\n","val = torch.tensor(val,dtype=torch.float64)\n","val_label = torch.tensor(val_label,dtype=torch.int64)\n","test = torch.tensor(test,dtype=torch.float64)\n","ss_label = torch.tensor(ss_label,dtype=torch.int64)\n","ss_test_label = torch.tensor(ss_test_label,dtype=torch.int64)\n","ss_val_label = torch.tensor(ss_val_label,dtype=torch.int64)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nLdEQfxCAmqC","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146680,"user_tz":-120,"elapsed":51468,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["\n","label_dis = torch.argmax(label,dim=2)\n","print(label_dis.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kd1QUaEu6sA3","colab_type":"text"},"source":["##Attention Mechisam\n"]},{"cell_type":"code","metadata":{"id":"Ujo8BD6vxJ7y","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146680,"user_tz":-120,"elapsed":51466,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","def attention(q, k, v, d_k, dropout=None):\n","    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n","    scores = F.softmax(scores, dim=-1)\n","        \n","    if dropout is not None:\n","        scores = dropout(scores)\n","        \n","    output = torch.matmul(scores, v)\n","    return output\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, heads, d_model):\n","        super().__init__()\n","        \n","        self.d_model = d_model\n","        self.d_k = d_model // heads\n","        self.h = heads\n","        \n","        self.q_linear = nn.Linear(d_model, d_model)\n","        self.v_linear = nn.Linear(d_model, d_model)\n","        self.k_linear = nn.Linear(d_model, d_model)\n","        #self.dropout = nn.Dropout(dropout)\n","        self.out = nn.Linear(d_model, d_model)\n","    \n","    def forward(self, q, k, v):\n","        \n","        # perform linear operation and split into h heads\n"," \n","        k = self.k_linear(k).view(-1, self.h, self.d_k)\n","        q = self.q_linear(q).view(-1, self.h, self.d_k)\n","        v = self.v_linear(v).view(-1, self.h, self.d_k)\n","    \n","        # transpose to get dimensions bs * h * sl * d_model\n","       \n","        k = k.transpose(0,1)\n","        q = q.transpose(0,1)\n","        v = v.transpose(0,1)\n","       \n","# calculate attention using function we will define next\n","        scores = attention(q, k, v, self.d_k)\n","        \n","        # concatenate heads and put through final linear layer\n","        concat = scores.transpose(0,1).contiguous()\\\n","        .view(-1, self.d_model)\n","        output = self.out(concat)\n","   \n","        return output\n","    \n","    \n","    \n","class FeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff):\n","        super().__init__() \n","        self.linear_1 = nn.Linear(d_model, d_ff)\n","        #self.dropout = nn.Dropout(dropout)\n","        self.linear_2 = nn.Linear(d_ff, d_model)\n","    def forward(self, x):\n","        x = F.relu(self.linear_1(x))\n","        x = self.linear_2(x)\n","        return x\n","   ############################################################################################################ \n","class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, max_len=700):\n","        self.d_model = d_model \n","        super(PositionalEncoding, self).__init__()\n","        #self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model).to('cuda')\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        if d_model%2 == 0:\n","            pe[:, 1::2] = torch.cos(position * div_term)\n","        else:\n","            pe[:, 1:10:2] = torch.cos(position * (div_term[0:1]))\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return x\n","\n","    #######################################################################################################\n","class Norm(nn.Module):\n","    def __init__(self, d_model, eps = 1e-6):\n","        super().__init__()\n","    \n","        self.size = d_model\n","        self.alpha = nn.Parameter(torch.ones(self.size))\n","        self.bias = nn.Parameter(torch.zeros(self.size))\n","        self.eps = eps\n","    def forward(self, x):\n","     \n","        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n","        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n","        return norm\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qIqDY_ZiWVgg","colab_type":"text"},"source":["## Model Backbone\n"]},{"cell_type":"code","metadata":{"id":"Ng67UUavxn3N","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146681,"user_tz":-120,"elapsed":51464,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["# build an encoder layer with one multi-head attention layer and one # feed-forward layer\n","class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, heads,d_ff):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.attn = MultiHeadAttention(heads, d_model)\n","        self.ff = FeedForward(d_model,d_ff)\n","        #self.dropout_1 = nn.Dropout(dropout)\n","        #self.dropout_2 = nn.Dropout(dropout)\n","            \n","    def forward(self, x):\n","        x2 = self.norm_1(x)\n","        x = x + self.attn(x2,x2,x2)\n","        x2 = self.norm_2(x)\n","        x = x + self.ff(x2)\n","        return x\n","    \n","# build a decoder layer with two multi-head attention layers and\n","# one feed-forward layer\n","class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, heads,d_ff):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.norm_3 = Norm(d_model)\n","        \n","        #self.dropout_1 = nn.Dropout(dropout)\n","        #self.dropout_2 = nn.Dropout(dropout)\n","        #self.dropout_3 = nn.Dropout(dropout)\n","        \n","        self.attn_1 = MultiHeadAttention(heads, d_model)\n","        self.attn_2 = MultiHeadAttention(heads, d_model)\n","        self.ff = FeedForward(d_model,d_ff)\n","       \n","        \n","    def forward(self, x, e_outputs):\n","       \n","        x2 = self.norm_1(x)\n","        x = x + self.attn_1(x2, x2, x2)\n","        x2 = self.norm_2(x)\n","        x = x + self.attn_2(x2, e_outputs, e_outputs)\n","        x2 = self.norm_3(x)\n","        x = x + self.ff(x2)\n","        return x\n","# We can then build a convenient cloning function that can generate multiple layers:\n","def get_clones(module, N):\n","    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, src_emb, N, heads,label_dim,d_ff):\n","        super().__init__()\n","        self.N = N\n","        self.pe = PositionalEncoding(22)\n","        self.layers = get_clones(EncoderLayer(src_emb, heads,d_ff), N)\n","        self.norm = Norm(src_emb)\n","        self.dimension_unify = nn.Linear(22,label_dim)\n","        \n","    def forward(self, x):\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x)\n","        x = self.norm(x)\n","        return self.dimension_unify(x)\n","    \n","class Decoder(nn.Module):\n","    def __init__(self, trg_emb, N, heads,d_ff,label_dim):\n","        super().__init__()\n","        self.N = N\n","        self.pe = PositionalEncoding(label_dim)\n","        self.layers = get_clones(DecoderLayer(trg_emb, heads,d_ff), N)\n","        self.norm = Norm(trg_emb)\n","        \n","    def forward(self, x, e_outputs):\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x, e_outputs)\n","        return self.norm(x)\n","    \n","class Transformer(nn.Module):\n","    def __init__(self, src_emb, trg_emb, N, heads,label_dim,d_ff):\n","        super().__init__()\n","        self.encoder = Encoder(src_emb, N, heads,label_dim,d_ff)\n","        self.decoder = Decoder(trg_emb, N, heads,d_ff,label_dim)\n","        self.out = nn.Linear(trg_emb, src_emb)\n","        \n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","        \n","    def forward(self, src, trg):\n","        e_outputs = self.encoder(src)\n","        d_output = self.decoder(trg, e_outputs)\n","        output = self.out(d_output)\n","        return d_output\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z8xBWevo65ar","colab_type":"text"},"source":["##Training and tesing the model"]},{"cell_type":"code","metadata":{"id":"pU0Sf9O3xfr7","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146681,"user_tz":-120,"elapsed":51456,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["\n","bs = 2\n","label_dim = 8\n","\n","class Dataloader(Dataset):\n","\n","    def __init__(self, train, label, transform=None):\n","        self.train = train\n","        self.label = label\n","        self.transform = None\n","\n","    def __len__(self):\n","        return len(self.train)\n","\n","    def __getitem__(self, idx):\n","        if self.transform:\n","            sample = self.transform(sample)\n","        else:\n","            return torch.tensor(self.train[idx]),torch.tensor(self.label[idx])\n","            #return torch.tensor(self.train[idx:idx+bs]),torch.tensor(self.label[idx:idx+bs])\n","\n","\n","#optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum = 0.1)\n","\n","loss_fn_1 = nn.CrossEntropyLoss()\n","\n","\n","print('The code can run properly')\n","\n","\n","def get_accuracy(output, trg):\n","    length_of_seq = output.shape[0]\n","    acc = (torch.sum(torch.argmax(output,dim=1) == torch.argmax(trg,dim=1))).item()/length_of_seq\n","    return acc\n","\n","    \n","\n","loader = Dataloader(train,label)\n","val_loader = Dataloader(val,val_label)\n","\n","n_head =[1,2]\n","n_enoderlayer = [2,4,6]\n","d_feedforward = [256,512,1024]\n","list_loss1 = []\n","list_loss2 = []\n","\n","list_a1 =[]\n","list_a2 =[]\n","\n","list_l = [list_loss1,list_loss2]\n","list_a = [list_a1,list_a2]\n","\n","for i in range(2):\n","\n","    h = n_head[i]\n","    l = list_l[i]\n","    a = list_a[i]\n","    \n","    model = Transformer(22,8,4,h,label_dim,256)\n","    model = model.double()\n","    model = model.to('cuda')\n","    epochs = 25\n","    ######################################################\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    with torch.autograd.set_detect_anomaly(True):\n","        for epoch in range(epochs):\n","            epoch_loss = 0\n","            train_acc = 0\n","            \n","            for i in range(0,500):\n","                loss = 0\n","                acc = 0\n","                e = np.random.randint(0,5000)\n","                src, trg = loader[e]\n","                \n","                src = src.to('cuda')\n","                trg = trg.to('cuda')\n","                optimizer.zero_grad()\n","                output = model(src,trg)\n","                src_mask = (src[:,21] != 1) \n","                          \n","                masked_trg = trg[src_mask]\n","                masked_output = output[src_mask]\n","                \n","                #for i in range(masked_trg.shape[0]):\n","                #    if 1 not in masked_trg[i]:\n","                #        print('haha')\n","              \n","                loss = loss_fn_1(masked_output, torch.argmax(masked_trg,1))\n","                acc = get_accuracy(masked_output,masked_trg)\n","                train_acc += acc\n","                #loss = loss_fn_1(masked_output[1], torch.argmax(masked_trg[1],1)) + loss_fn_1(masked_output[0], torch.argmax(masked_trg[0],1))  \n","                loss.backward()\n","                optimizer.step()\n","                epoch_loss += float(loss)  \n","            l.append(epoch_loss)\n","            a.append(train_acc/500)\n","       \n","            \n","            print(f'After epoch {epoch+1}: The loss is {epoch_loss}')\n","            print(f'After epoch {epoch+1}: The accuracy is {train_acc/500}')\n","    \n","\n","\n","\n","    # Specify a path\n","    PATH = \"transformer.pt\"\n","\n","    # Save\n","    torch.save(model.state_dict(), PATH)\n","\n","    # Load\n","    model = Transformer(22,8,4,h,label_dim,256)\n","    model = model.to('cuda')\n","    model = model.double()\n","    model.load_state_dict(torch.load(PATH))\n","    model.eval()\n","\n","    test_loader = Dataloader(test,test_label)\n","    test_epoch_loss = 0\n","    test_epoch_acc = 0\n","    for i in range(0,267):\n","          src, trg = test_loader[i]\n","          src = src.to('cuda')\n","          trg = trg.to('cuda')\n","          src_mask = (src[:,21] != 1)            \n","          masked_src = src[src_mask]\n","          masked_trg = trg[src_mask]\n","          optimizer.zero_grad()\n","          output = model(masked_src,masked_trg)\n","          test_loss = loss_fn_1(output, torch.argmax(masked_trg,1))\n","          test_acc = get_accuracy(output,masked_trg)\n","          test_epoch_acc += test_acc\n","          test_epoch_loss += test_loss\n","    print(f'The loss is {test_epoch_loss}')\n","    print(f'The accuracy is {test_epoch_acc/267}')\n","\n","print(list_l[0],list_l[1],list_a[0],list_a[1])\n","list_epoch = np.arange(epochs)\n","plt.plot(list_l[0],list_epoch,label='1 head')\n","plt.plot(list_l[1],list_epoch,label='2 heads')\n","plt.ylabel('Loss')\n","plt.xlabel('Number of Epoches')\n","plt.legend()\n","plt.show()\n","        \n","        \n","plt.plot(list_a[0],list_epoch,label='1 head')\n","plt.plot(list_a[1],list_epoch,label='2 heads')\n","plt.ylabel('Loss')\n","plt.xlabel('Number of Epoches')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n","      \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3nUZCi6ppiD-","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146682,"user_tz":-120,"elapsed":51443,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["print(list_a[0])\n","print(list_a[1])\n","print(list_l[0])\n","print(list_l[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kzBhS7NUuVt","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146682,"user_tz":-120,"elapsed":51430,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["n_enoderlayer = [2,4,6]\n","d_feedforward = [256,512,1024]\n","list_loss1 = []\n","list_loss2 = []\n","list_loss3 = []\n","list_a1 =[]\n","list_a2 =[]\n","list_a3 =[]\n","list_l = [list_loss1,list_loss2,list_loss3]\n","list_a = [list_a1,list_a2,list_a3]\n"," \n","\n","for i in range(3):\n","\n","\n","    l = list_l[i]\n","    a = list_a[i]\n","    \n","    model = Transformer(22,8,h,2,label_dim,256)\n","    model = model.double()\n","    model = model.to('cuda')\n","    epochs = 20\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    with torch.autograd.set_detect_anomaly(True):\n","        for epoch in range(epochs):\n","            epoch_loss = 0\n","            train_acc = 0\n","            \n","            for i in range(0,500):\n","                loss = 0\n","                acc = 0\n","                e = np.random.randint(0,5000)\n","                src, trg = loader[e]\n","                \n","                src = src.to('cuda')\n","                trg = trg.to('cuda')\n","                optimizer.zero_grad()\n","                output = model(src,trg)\n","                src_mask = (src[:,21] != 1) \n","                          \n","                masked_trg = trg[src_mask]\n","                masked_output = output[src_mask]\n","                \n","                #for i in range(masked_trg.shape[0]):\n","                #    if 1 not in masked_trg[i]:\n","                #        print('haha')\n","              \n","                loss = loss_fn_1(masked_output, torch.argmax(masked_trg,1))\n","                acc = get_accuracy(masked_output,masked_trg)\n","                train_acc += acc\n","                #loss = loss_fn_1(masked_output[1], torch.argmax(masked_trg[1],1)) + loss_fn_1(masked_output[0], torch.argmax(masked_trg[0],1))  \n","                loss.backward()\n","                optimizer.step()\n","                epoch_loss += float(loss)  \n","            l.append(epoch_loss)\n","            a.append(train_acc/500)\n","       \n","            \n","            print(f'After epoch {epoch+1}: The loss is {epoch_loss}')\n","            print(f'After epoch {epoch+1}: The accuracy is {train_acc/500}')\n","    \n","\n","\n","\n","    # Specify a path\n","    PATH = \"transformer.pt\"\n","\n","    # Save\n","    torch.save(model.state_dict(), PATH)\n","\n","    # Load\n","    model = Transformer(22,8,h,2,label_dim,256)\n","    model = model.to('cuda')\n","    model = model.double()\n","    model.load_state_dict(torch.load(PATH))\n","    model.eval()\n","\n","    test_loader = Dataloader(test,test_label)\n","    test_epoch_loss = 0\n","    test_epoch_acc = 0\n","    for i in range(0,267):\n","          src, trg = test_loader[i]\n","          src = src.to('cuda')\n","          trg = trg.to('cuda')\n","          src_mask = (src[:,21] != 1)            \n","          masked_src = src[src_mask]\n","          masked_trg = trg[src_mask]\n","          optimizer.zero_grad()\n","          output = model(masked_src,masked_trg)\n","          test_loss = loss_fn_1(output, torch.argmax(masked_trg,1))\n","          test_acc = get_accuracy(output,masked_trg)\n","          test_epoch_acc += test_acc\n","          test_epoch_loss += test_loss\n","    print(f'The loss is {test_epoch_loss}')\n","    print(f'The accuracy is {test_epoch_acc/267}')\n","\n","list_epoch = np.arange(epochs)\n","plt.plot(list_l[0],list_epoch,label='2 layers')\n","plt.plot(list_l[1],list_epoch,label='4 layers')\n","plt.plot(list_l[2],list_epoch,label='6 layers')\n","plt.ylabel('Loss')\n","plt.xlabel('Number of Epoches')\n","plt.legend()\n","plt.show()\n","        \n","        \n","plt.plot(list_a[0],list_epoch,label='2 layers')\n","plt.plot(list_a[1],list_epoch,label='4 layers')\n","plt.plot(list_a[2],list_epoch,label='6 layers')\n","\n","plt.xlabel('Number of Epoches')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7C0R6Si2zIAz","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146683,"user_tz":-120,"elapsed":51419,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["print(list_a[0])\n","print(list_a[1])\n","print(list_a[2])\n","print(list_l[0])\n","print(list_l[1])\n","print(list_l[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_JVJnymJl49","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146684,"user_tz":-120,"elapsed":51407,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["d_feedforward = [256,512,1024]\n","list_loss1 = []\n","list_loss2 = []\n","list_loss3 = []\n","list_a1 =[]\n","list_a2 =[]\n","list_a3 =[]\n","list_l = [list_loss1,list_loss2,list_loss3]\n","list_a = [list_a1,list_a2,list_a3]\n"," \n","\n","for i in range(3):\n","\n","\n","    l = list_l[i]\n","    a = list_a[i]\n","    \n","    model = Transformer(22,8,4,2,label_dim,h)\n","    model = model.double()\n","    model = model.to('cuda')\n","    epochs = 30\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    with torch.autograd.set_detect_anomaly(True):\n","        for epoch in range(epochs):\n","            epoch_loss = 0\n","            train_acc = 0\n","            \n","            for i in range(0,1000):\n","                loss = 0\n","                acc = 0\n","                e = np.random.randint(0,5000)\n","                src, trg = loader[e]\n","                \n","                src = src.to('cuda')\n","                trg = trg.to('cuda')\n","                optimizer.zero_grad()\n","                output = model(src,trg)\n","                src_mask = (src[:,21] != 1) \n","                          \n","                masked_trg = trg[src_mask]\n","                masked_output = output[src_mask]\n","                \n","                #for i in range(masked_trg.shape[0]):\n","                #    if 1 not in masked_trg[i]:\n","                #        print('haha')\n","              \n","                loss = loss_fn_1(masked_output, torch.argmax(masked_trg,1))\n","                acc = get_accuracy(masked_output,masked_trg)\n","                train_acc += acc\n","                #loss = loss_fn_1(masked_output[1], torch.argmax(masked_trg[1],1)) + loss_fn_1(masked_output[0], torch.argmax(masked_trg[0],1))  \n","                loss.backward()\n","                optimizer.step()\n","                epoch_loss += float(loss)  \n","            l.append(epoch_loss)\n","            a.append(train_acc/1000)\n","       \n","            \n","            print(f'After epoch {epoch+1}: The loss is {epoch_loss}')\n","            print(f'After epoch {epoch+1}: The accuracy is {train_acc/1000}')\n","    \n","\n","\n","\n","    # Specify a path\n","    PATH = \"transformer.pt\"\n","\n","    # Save\n","    torch.save(model.state_dict(), PATH)\n","\n","    # Load\n","    model = Transformer(22,8,4,2,label_dim,h)\n","    model = model.to('cuda')\n","    model = model.double()\n","    model.load_state_dict(torch.load(PATH))\n","    model.eval()\n","\n","    test_loader = Dataloader(test,test_label)\n","    test_epoch_loss = 0\n","    test_epoch_acc = 0\n","    for i in range(0,267):\n","          src, trg = test_loader[i]\n","          src = src.to('cuda')\n","          trg = trg.to('cuda')\n","          src_mask = (src[:,21] != 1)            \n","          masked_src = src[src_mask]\n","          masked_trg = trg[src_mask]\n","          optimizer.zero_grad()\n","          output = model(masked_src,masked_trg)\n","          test_loss = loss_fn_1(output, torch.argmax(masked_trg,1))\n","          test_acc = get_accuracy(output,masked_trg)\n","          test_epoch_acc += test_acc\n","          test_epoch_loss += test_loss\n","    print(f'The loss is {test_epoch_loss}')\n","    print(f'The accuracy is {test_epoch_acc/267}')\n","\n","list_epoch = np.arange(epochs)\n","plt.plot(list_l[0],list_epoch,label='256')\n","plt.plot(list_l[1],list_epoch,label='512')\n","plt.plot(list_l[2],list_epoch,label='1024')\n","plt.ylabel('Loss')\n","plt.xlabel('Number of Epoches')\n","plt.legend()\n","plt.show()\n","        \n","        \n","plt.plot(list_a[0],list_epoch,label='256')\n","plt.plot(list_a[1],list_epoch,label='512')\n","plt.plot(list_a[2],list_epoch,label='1024')\n","plt.xlabel('Number of Epoches')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Me3HOTgAzOsP","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146684,"user_tz":-120,"elapsed":51394,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["\n","print(list_a[0])\n","print(list_a[1])\n","print(list_a[2])\n","print(list_l[0])\n","print(list_l[1])\n","print(list_l[2])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mmjrNk-z0gxy","colab_type":"text"},"source":["## Including the Solvent Accessibility "]},{"cell_type":"code","metadata":{"id":"arPvTlaTl2Rf","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146685,"user_tz":-120,"elapsed":51383,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["bs = 2\n","label_dim = 8\n","\n","\n","#for i in range(267):\n","                #    val_src, val_trg = val_loader[i]\n","                #    val_src = val_src.to('cuda')\n","                #    val_trg = val_trg.to('cuda')\n","                #    val_output = model(val_src,val_trg)\n","                #    val_src_mask = (val_src[:,21] != 1) \n","                #    \n","                #    val_masked_trg = val_trg[val_src_mask]\n","                #    masked_output = val_output[val_src_mask]\n","                #    \n","                #    val_acc = get_accuracy(masked_output,val_masked_trg)\n","                #    total_acc.append(val_acc)\n","                #    print(sum(total_acc)/len(total_acc))\n","model = Transformer(22,8,1,1,label_dim,128)\n","model = model.double()\n","model = model.to('cuda')\n","epochs = 30\n","l1 = []\n","a1 = []\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","with torch.autograd.set_detect_anomaly(True):\n","    for epoch in range(epochs):\n","        epoch_loss = 0\n","        train_acc = 0\n","        \n","        for i in range(0,2000):\n","            loss = 0\n","            acc = 0\n","            e = np.random.randint(0,5000)\n","            src, trg = loader[e]\n","            src = src[:,8]\n","            src1 = src[:,8:13]\n","            src = src.to('cuda')\n","            trg = trg.to('cuda')\n","            optimizer.zero_grad()\n","            output = model(src,trg)\n","            src_mask = (src[:,21] != 1) \n","                      \n","            masked_trg = trg[src_mask]\n","            masked_output = output[src_mask]\n","            \n","            #for i in range(masked_trg.shape[0]):\n","            #    if 1 not in masked_trg[i]:\n","            #        print('haha')\n","            \n","            loss = loss_fn_1(masked_output, torch.argmax(masked_trg,1))\n","            acc = get_accuracy(masked_output,masked_trg)\n","            train_acc += acc\n","            #loss = loss_fn_1(masked_output[1], torch.argmax(masked_trg[1],1)) + loss_fn_1(masked_output[0], torch.argmax(masked_trg[0],1))  \n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += float(loss)  \n","        l1.append(epoch_loss)\n","        a1.append(train_acc/500)\n","    \n","        \n","        print(f'After epoch {epoch+1}: The loss is {epoch_loss}')\n","        print(f'After epoch {epoch+1}: The accuracy is {train_acc/2000}')\n","\n","\n","\n","\n","# Specify a path\n","PATH = \"transformer.pt\"\n","\n","# Save\n","torch.save(model.state_dict(), PATH)\n","\n","# Load\n","model = Transformer(22,8,1,1,label_dim,128)\n","model = model.to('cuda')\n","model = model.double()\n","model.load_state_dict(torch.load(PATH))\n","model.eval()\n","\n","test_loader = Dataloader(test,test_label)\n","test_epoch_loss = 0\n","test_epoch_acc = 0\n","for i in range(0,267):\n","      src, trg = test_loader[i]\n","      src = src.to('cuda')\n","      trg = trg.to('cuda')\n","      src_mask = (src[:,21] != 1)            \n","      masked_src = src[src_mask]\n","      masked_trg = trg[src_mask]\n","      optimizer.zero_grad()\n","      output = model(masked_src,masked_trg)\n","      test_loss = loss_fn_1(output, torch.argmax(masked_trg,1))\n","      test_acc = get_accuracy(output,masked_trg)\n","      test_epoch_acc += test_acc\n","      test_epoch_loss += test_loss\n","print(f'The loss is {test_epoch_loss}')\n","print(f'The accuracy is {test_epoch_acc/267}')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9HvMidRLzpP6","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146686,"user_tz":-120,"elapsed":51371,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["print([i * 2.5 for i in a1])\n","print(l1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"49WKXUFoRBkc","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146687,"user_tz":-120,"elapsed":51361,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["loader1 = Dataloader(train,ss_label)\n","model = Transformer(22,13,1,1,13,128)\n","model = model.double()\n","model = model.to('cuda')\n","epochs = 30\n","l2 = []\n","a2 = []\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","with torch.autograd.set_detect_anomaly(True):\n","    for epoch in range(epochs):\n","        epoch_loss = 0\n","        train_acc = 0\n","        \n","        for i in range(0,2000):\n","            loss = 0\n","            acc = 0\n","            e = np.random.randint(0,5000)\n","            src, trg = loader1[e]\n","            \n","            src = src.to('cuda')\n","            trg = trg.to('cuda')\n","            optimizer.zero_grad()\n","            output = model(src,trg)\n","            src_mask = (src[:,21] != 1) \n","                      \n","            masked_trg = trg[src_mask]\n","            masked_output = output[src_mask]\n","            \n","            #for i in range(masked_trg.shape[0]):\n","            #    if 1 not in masked_trg[i]:\n","            #        print('haha')\n","          \n","            loss = loss_fn_1(masked_output, torch.argmax(masked_trg,1))\n","            acc = get_accuracy(masked_output,masked_trg)\n","            train_acc += acc\n","            #loss = loss_fn_1(masked_output[1], torch.argmax(masked_trg[1],1)) + loss_fn_1(masked_output[0], torch.argmax(masked_trg[0],1))  \n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += float(loss)  \n","        l2.append(epoch_loss)\n","        a2.append(train_acc/2000)\n","    \n","        \n","        print(f'After epoch {epoch+1}: The loss is {epoch_loss}')\n","        print(f'After epoch {epoch+1}: The accuracy is {train_acc/2000}')\n","\n","\n","\n","\n","# Specify a path\n","PATH = \"transformer.pt\"\n","\n","# Save\n","torch.save(model.state_dict(), PATH)\n","\n","# Load\n","model = Transformer(22,13,1,1,13,128)\n","model = model.to('cuda')\n","model = model.double()\n","model.load_state_dict(torch.load(PATH))\n","model.eval()\n","\n","test_loader1 = Dataloader(test,ss_test_label)\n","test_epoch_loss = 0\n","test_epoch_acc = 0\n","for i in range(0,267):\n","      src, trg = test_loader1[i]\n","      src = src.to('cuda')\n","      trg = trg.to('cuda')\n","      src_mask = (src[:,21] != 1)            \n","      masked_src = src[src_mask]\n","      masked_trg = trg[src_mask]\n","      optimizer.zero_grad()\n","      output = model(masked_src,masked_trg)\n","      test_loss = loss_fn_1(output, torch.argmax(masked_trg,1))\n","      test_acc = get_accuracy(output,masked_trg)\n","      test_epoch_acc += test_acc\n","      test_epoch_loss += test_loss\n","print(f'The loss is {test_epoch_loss}')\n","print(f'The accuracy is {test_epoch_acc/267}')\n","\n","list_epoch = np.arange(epochs)\n","plt.plot(l1,list_epoch,label='eight state')\n","plt.plot(l2,list_epoch,label='three state')\n","\n","plt.ylabel('Loss')\n","plt.xlabel('Number of Epoches')\n","plt.legend()\n","plt.show()\n","        \n","        \n","plt.plot(a1,list_epoch,label='Without Solvent Accessibility')\n","plt.plot(a2,list_epoch,label='With Solvent Accessibility')\n","\n","\n","plt.ylabel('Loss')\n","plt.xlabel('Number of Epoches')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Ggcf9La6VZN","colab_type":"text"},"source":["##Three State Label"]},{"cell_type":"code","metadata":{"id":"OZbjuS240r04","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146687,"user_tz":-120,"elapsed":51359,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dpFEBSkqVE9z","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146688,"user_tz":-120,"elapsed":51349,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["model = Transformer(22,8,1,1,label_dim,128)\n","model = model.double()\n","model = model.to('cuda')\n","epochs = 30\n","l1 = []\n","a1 = []\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","with torch.autograd.set_detect_anomaly(True):\n","    for epoch in range(epochs):\n","        epoch_loss = 0\n","        train_acc = 0\n","        \n","        for i in range(0,2000):\n","            loss = 0\n","            acc = 0\n","            e = np.random.randint(0,5000)\n","            src, trg = loader[e]\n","            \n","            src = src.to('cuda')\n","            trg = trg.to('cuda')\n","            optimizer.zero_grad()\n","            output = model(src,trg)\n","            src_mask = (src[:,21] != 1) \n","                      \n","            masked_trg = trg[src_mask]\n","            masked_output = output[src_mask]\n","            \n","            #for i in range(masked_trg.shape[0]):\n","            #    if 1 not in masked_trg[i]:\n","            #        print('haha')\n","          \n","            loss = loss_fn_1(masked_output, torch.argmax(masked_trg,1))\n","            acc = get_accuracy(masked_output,masked_trg)\n","            train_acc += acc\n","            #loss = loss_fn_1(masked_output[1], torch.argmax(masked_trg[1],1)) + loss_fn_1(masked_output[0], torch.argmax(masked_trg[0],1))  \n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += float(loss)  \n","        l1.append(epoch_loss)\n","        a1.append(train_acc/2000)\n","    \n","        \n","        print(f'After epoch {epoch+1}: The loss is {epoch_loss}')\n","        print(f'After epoch {epoch+1}: The accuracy is {train_acc/2000}')\n","\n","\n","\n","\n","# Specify a path\n","PATH = \"transformer.pt\"\n","\n","# Save\n","torch.save(model.state_dict(), PATH)\n","\n","# Load\n","model = Transformer(22,8,1,1,label_dim,128)\n","model = model.to('cuda')\n","model = model.double()\n","model.load_state_dict(torch.load(PATH))\n","model.eval()\n","\n","test_loader = Dataloader(test,test_label)\n","test_epoch_loss = 0\n","test_epoch_acc = 0\n","for i in range(0,267):\n","      src, trg = test_loader[i]\n","      src = src.to('cuda')\n","      trg = trg.to('cuda')\n","      src_mask = (src[:,21] != 1)            \n","      masked_src = src[src_mask]\n","      masked_trg = trg[src_mask]\n","      optimizer.zero_grad()\n","      output = model(masked_src,masked_trg)\n","      test_loss = loss_fn_1(output, torch.argmax(masked_trg,1))\n","      test_acc = get_accuracy(output,masked_trg)\n","      test_epoch_acc += test_acc\n","      test_epoch_loss += test_loss\n","print(f'The loss is {test_epoch_loss}')\n","print(f'The accuracy is {test_epoch_acc/267}')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8uJbnybcWOxq","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146688,"user_tz":-120,"elapsed":51339,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["loader1 = Dataloader(train,label_3)\n","model = Transformer(22,3,1,1,3,128)\n","model = model.double()\n","model = model.to('cuda')\n","epochs = 30\n","l2 = []\n","a2 = []\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","with torch.autograd.set_detect_anomaly(True):\n","    for epoch in range(epochs):\n","        epoch_loss = 0\n","        train_acc = 0\n","        \n","        for i in range(0,2000):\n","            loss = 0\n","            acc = 0\n","            e = np.random.randint(0,5000)\n","            src, trg = loader1[e]\n","            \n","            src = src.to('cuda')\n","            trg = trg.to('cuda')\n","            optimizer.zero_grad()\n","            output = model(src,trg)\n","            src_mask = (src[:,21] != 1) \n","                      \n","            masked_trg = trg[src_mask]\n","            masked_output = output[src_mask]\n","            \n","            #for i in range(masked_trg.shape[0]):\n","            #    if 1 not in masked_trg[i]:\n","            #        print('haha')\n","          \n","            loss = loss_fn_1(masked_output, torch.argmax(masked_trg,1))\n","            acc = get_accuracy(masked_output,masked_trg)\n","            train_acc += acc\n","            #loss = loss_fn_1(masked_output[1], torch.argmax(masked_trg[1],1)) + loss_fn_1(masked_output[0], torch.argmax(masked_trg[0],1))  \n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += float(loss)  \n","        l2.append(epoch_loss)\n","        a2.append(train_acc/200)\n","    \n","        \n","        print(f'After epoch {epoch+1}: The loss is {epoch_loss}')\n","        print(f'After epoch {epoch+1}: The accuracy is {train_acc/2000}')\n","\n","\n","\n","\n","# Specify a path\n","PATH = \"transformer.pt\"\n","\n","# Save\n","torch.save(model.state_dict(), PATH)\n","\n","# Load\n","model = Transformer(22,3,1,1,3,128)\n","model = model.to('cuda')\n","model = model.double()\n","model.load_state_dict(torch.load(PATH))\n","model.eval()\n","\n","test_loader1 = Dataloader(test,test_label_3)\n","test_epoch_loss = 0\n","test_epoch_acc = 0\n","for i in range(0,267):\n","      src, trg = test_loader1[i]\n","      src = src.to('cuda')\n","      trg = trg.to('cuda')\n","      src_mask = (src[:,21] != 1)            \n","      masked_src = src[src_mask]\n","      masked_trg = trg[src_mask]\n","      optimizer.zero_grad()\n","      output = model(masked_src,masked_trg)\n","      test_loss = loss_fn_1(output, torch.argmax(masked_trg,1))\n","      test_acc = get_accuracy(output,masked_trg)\n","      test_epoch_acc += test_acc\n","      test_epoch_loss += test_loss\n","print(f'The loss is {test_epoch_loss}')\n","print(f'The accuracy is {test_epoch_acc/267}')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"65JV9-E7A9NW","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146689,"user_tz":-120,"elapsed":51329,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["print(a2)\n","print(l2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_2iSeCJWO5f","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146689,"user_tz":-120,"elapsed":51326,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################\n","############################################################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vw-kg_l_WO_h","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146690,"user_tz":-120,"elapsed":51324,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vdgaqw4s0nm2","colab_type":"text"},"source":["##Validate the model"]},{"cell_type":"code","metadata":{"id":"6VNYaMX0WPLd","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146690,"user_tz":-120,"elapsed":51322,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_vv9uUV7WPJc","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146691,"user_tz":-120,"elapsed":51314,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qtO5DHfuWPHZ","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146691,"user_tz":-120,"elapsed":51312,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdeRISgWWPFL","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146691,"user_tz":-120,"elapsed":51309,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"08I8ZHTCWPCn","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146692,"user_tz":-120,"elapsed":51308,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nGkGnMXL6D0u","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146692,"user_tz":-120,"elapsed":51306,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjxS4CojbhYb","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146693,"user_tz":-120,"elapsed":51305,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20SnJUVtzyOj","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146693,"user_tz":-120,"elapsed":51302,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[" \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zzj6Fi8ZSL-F","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146694,"user_tz":-120,"elapsed":51301,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZEqYoeNbEyR4","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146694,"user_tz":-120,"elapsed":51299,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CN3nHqqseN20","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597923146695,"user_tz":-120,"elapsed":51297,"user":{"displayName":"Nico Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSsKMWzHXOtXHZ-O337gr-ELeH5ap_eoCOh9q9=s64","userId":"05280793383606486472"}}},"source":[""],"execution_count":null,"outputs":[]}]}